{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105442db",
   "metadata": {},
   "source": [
    "# Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8773ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install diffusers for demo\n",
    "!pip install diffusers\n",
    "!pip install torch\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a238efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from IPython.display import display, Image\n",
    "import PIL\n",
    "\n",
    "import pytorch_lightning as L\n",
    "from diffusers import (\n",
    "    StableDiffusion3Pipeline,\n",
    "    StableDiffusion3ControlNetPipeline,\n",
    ")\n",
    "from diffusers.models import SD3ControlNetModel\n",
    "from diffusers.utils import load_image\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Fix seed\n",
    "L.seed_everything(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b930cad",
   "metadata": {},
   "source": [
    "# Load Stable Diffusion 3 and Generate Images from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare prompts\n",
    "prompts = [\"a photo of an astronaut riding a horse on mars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f2b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_id = \"stabilityai/stable-diffusion-3-medium-diffusers\"\n",
    "pipe = StableDiffusion3Pipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe.enable_model_cpu_offload()  # NOTE: This option is necessary for VRAM-efficient inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Images (Takes less than a minute on RTX 3090)\n",
    "L.seed_everything(2025)  # for reproducibility\n",
    "\n",
    "images = pipe(\n",
    "    prompts,\n",
    "    negative_prompt=\"\",\n",
    "    num_inference_steps=28,\n",
    "    guidance_scale=7.0,\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51832f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Images\n",
    "for image_idx, image in enumerate(images):\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0aeb8",
   "metadata": {},
   "source": [
    "# Playing with Classifier-Free Guidance Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_scales = [0.0, 7.0, 14.0, 21.0]\n",
    "cfg_results = []\n",
    "for cfg_scale in tqdm(cfg_scales):\n",
    "    images = pipe(\n",
    "        prompts,\n",
    "        negative_prompt=\"\",\n",
    "        num_inference_steps=28,\n",
    "        guidance_scale=cfg_scale,\n",
    "    ).images\n",
    "    cfg_results.extend(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Images\n",
    "cfg_results_ = [np.array(image) for image in cfg_results]\n",
    "cfg_results_ = np.concatenate(cfg_results_, axis=1)\n",
    "display(PIL.Image.fromarray(cfg_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2e920c",
   "metadata": {},
   "source": [
    "# Depth-Guided Image Generation with ControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: https://huggingface.co/InstantX/SD3-Controlnet-Depth\n",
    "model_id = \"stabilityai/stable-diffusion-3-medium-diffusers\"\n",
    "\n",
    "# load pipeline\n",
    "controlnet = SD3ControlNetModel.from_pretrained(\"InstantX/SD3-Controlnet-Depth\")\n",
    "pipe_controlnet = StableDiffusion3ControlNetPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    controlnet=controlnet\n",
    ")\n",
    "pipe_controlnet.enable_model_cpu_offload()\n",
    "\n",
    "# config\n",
    "control_image = load_image(\"https://huggingface.co/InstantX/SD3-Controlnet-Depth/resolve/main/images/depth.jpeg\")\n",
    "prompt = \"a panda cub, captured in a close-up, in forest, is perched on a tree trunk. good composition, Photography, the cub's ears, a fluffy black, are tucked behind its head, adding a touch of whimsy to its appearance. a lush tapestry of green leaves in the background. depth of field, National Geographic\"\n",
    "n_prompt = \"bad hands, blurry, NSFW, nude, naked, porn, ugly, bad quality, worst quality\"\n",
    "control_image = control_image.resize((512, 512))  # resize to reduce VRAM usage\n",
    "\n",
    "# to reproduce result in our example\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(2025)\n",
    "image = pipe_controlnet(\n",
    "    prompt, \n",
    "    negative_prompt=n_prompt, \n",
    "    control_image=control_image, \n",
    "    controlnet_conditioning_scale=0.5,\n",
    "    guidance_scale=7.0,\n",
    "    generator=generator\n",
    ").images[0]\n",
    "image = image.resize((512, 512))\n",
    "image.save('image.jpg')\n",
    "\n",
    "# show the results\n",
    "summary = np.concatenate(\n",
    "    [np.array(control_image), np.array(image)],\n",
    "    axis=1\n",
    ")\n",
    "summary = PIL.Image.fromarray(summary)\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafd33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: https://huggingface.co/InstantX/SD3-Controlnet-Depth\n",
    "model_id = \"stabilityai/stable-diffusion-3-medium-diffusers\"\n",
    "\n",
    "# load pipeline\n",
    "controlnet = SD3ControlNetModel.from_pretrained(\"InstantX/SD3-Controlnet-Depth\")\n",
    "pipe_controlnet = StableDiffusion3ControlNetPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    controlnet=controlnet\n",
    ")\n",
    "pipe_controlnet.enable_model_cpu_offload()\n",
    "\n",
    "# config\n",
    "control_image = load_image(\"https://huggingface.co/InstantX/SD3-Controlnet-Depth/resolve/main/images/depth.jpeg\")\n",
    "prompt = \"a panda cub, captured in a close-up, in forest, is perched on a tree trunk. good composition, Photography, the cub's ears, a fluffy black, are tucked behind its head, adding a touch of whimsy to its appearance. a lush tapestry of green leaves in the background. depth of field, National Geographic\"\n",
    "n_prompt = \"bad hands, blurry, NSFW, nude, naked, porn, ugly, bad quality, worst quality\"\n",
    "control_image = control_image.resize((512, 512))  # resize to reduce VRAM usage\n",
    "\n",
    "# to reproduce result in our example\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(2025)\n",
    "image = pipe_controlnet(\n",
    "    prompt, \n",
    "    negative_prompt=n_prompt, \n",
    "    control_image=control_image, \n",
    "    controlnet_conditioning_scale=0.0,  # NOTE: Set to 0 to disable controlnet\n",
    "    guidance_scale=7.0,\n",
    "    generator=generator\n",
    ").images[0]\n",
    "image = image.resize((512, 512))\n",
    "image.save('image_no_control.jpg')\n",
    "\n",
    "# show the results\n",
    "summary = np.concatenate(\n",
    "    [np.array(control_image), np.array(image)],\n",
    "    axis=1\n",
    ")\n",
    "summary = PIL.Image.fromarray(summary)\n",
    "display(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ld3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
